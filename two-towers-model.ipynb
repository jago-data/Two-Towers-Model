{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 22:58:40.588982: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-11 22:58:40.664726: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-11 22:58:41.105958: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-11 22:58:41.106026: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-11 22:58:41.175590: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-11 22:58:41.298468: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-11 22:58:41.299846: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 22:58:43.372014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hartonosng/miniforge3/envs/py_env/lib/python3.9/functools.py:888: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/hartonosng/miniforge3/envs/py_env/lib/python3.9/functools.py:888: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "329/329 [==============================] - 2s 3ms/step - loss: 6.3177 - accuracy: 0.0274 - val_loss: 5.4501 - val_accuracy: 0.0638\n",
      "Epoch 2/5\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 5.1035 - accuracy: 0.0517 - val_loss: 5.4501 - val_accuracy: 0.0638\n",
      "Epoch 3/5\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 5.1035 - accuracy: 0.0334 - val_loss: 5.4501 - val_accuracy: 0.0638\n",
      "Epoch 4/5\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 5.1035 - accuracy: 0.0456 - val_loss: 5.4501 - val_accuracy: 0.0638\n",
      "Epoch 5/5\n",
      "329/329 [==============================] - 1s 2ms/step - loss: 5.1035 - accuracy: 0.0334 - val_loss: 5.4501 - val_accuracy: 0.0638\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.1211 - accuracy: 0.0319\n",
      "Test Loss: 5.121081829071045\n",
      "Test Accuracy: 0.03191489353775978\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " product_input (InputLayer)  [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_tower (Functional)     (None, 8)                    2664      ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " product_tower (Functional)  (None, 8)                    2600      ['product_input[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 8)                    0         ['user_tower[0][0]',          \n",
      " da)                                                                 'product_tower[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLa  (None,)                      0         ['tf.math.multiply[0][0]']    \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5264 (20.56 KB)\n",
      "Trainable params: 5264 (20.56 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Generate synthetic user_data\n",
    "customer_ids = [f'C{i}' for i in range(1, 1001)]\n",
    "age_groups = ['20-30', '30-40', '40-50', '50-60', '60-70']\n",
    "segments = ['Standard', 'Premium']\n",
    "incomes = np.random.randint(30000, 100000, size=1000)\n",
    "aums = np.random.randint(50000, 150000, size=1000)\n",
    "\n",
    "user_data = pl.DataFrame({\n",
    "    'customerid': customer_ids,\n",
    "    'age_group': np.random.choice(age_groups, size=1000),\n",
    "    'segment': np.random.choice(segments, size=1000),\n",
    "    'income': incomes,\n",
    "    'AUM': aums\n",
    "})\n",
    "\n",
    "# Generate synthetic interaction_data\n",
    "product_codes = [f'P{i}' for i in range(1, 21)]\n",
    "interaction_data = []\n",
    "num_interactions = 5000\n",
    "\n",
    "for _ in range(num_interactions):\n",
    "    customer_id = random.choice(customer_ids)\n",
    "    product_code = random.choice(product_codes)\n",
    "    interaction_data.append([customer_id, product_code])\n",
    "\n",
    "interaction_data_df = pl.DataFrame(interaction_data, schema=['customerid', 'product_code'])\n",
    "\n",
    "# Generate synthetic product_data\n",
    "product_names = [f'Product {i}' for i in range(1, 21)]\n",
    "product_types = ['Bond', 'Mutual Fund']\n",
    "performances = np.random.uniform(5.0, 10.0, size=20)\n",
    "\n",
    "product_data = pl.DataFrame({\n",
    "    'product_code': product_codes,\n",
    "    'product_name': product_names,\n",
    "    'product_type': np.random.choice(product_types, size=20),\n",
    "    'performance': performances\n",
    "})\n",
    "\n",
    "# Encode categorical columns\n",
    "def encode_data(df, categorical_columns):\n",
    "    df_encoded = df.to_pandas()\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "    return pl.from_pandas(df_encoded)\n",
    "\n",
    "user_data_encoded = encode_data(user_data, ['age_group', 'segment'])\n",
    "product_data_encoded = encode_data(product_data, ['product_type', 'product_name'])\n",
    "\n",
    "# Generate negative samples\n",
    "def generate_negative_samples(interaction_data, product_data, num_negatives=1):\n",
    "    all_products = set(product_data['product_code'].to_list())\n",
    "    negative_samples = []\n",
    "\n",
    "    for row in interaction_data.iter_rows():\n",
    "        user = row[0]\n",
    "        positive_product = row[1]\n",
    "\n",
    "        # Generate negative samples\n",
    "        for _ in range(num_negatives):\n",
    "            negative_product = random.choice(list(all_products - set([positive_product])))\n",
    "            negative_samples.append([user, negative_product, 0])  # Label 0 for negative\n",
    "\n",
    "    return pl.DataFrame(negative_samples, schema=['customerid', 'product_code', 'label'])\n",
    "\n",
    "interaction_data_df = interaction_data_df.with_columns(pl.lit(1).alias('label'))\n",
    "negative_samples = generate_negative_samples(interaction_data_df, product_data, num_negatives=2)\n",
    "\n",
    "# Ensure consistent types\n",
    "interaction_data_df = interaction_data_df.with_columns([\n",
    "    pl.col('customerid').cast(pl.Utf8),\n",
    "    pl.col('product_code').cast(pl.Utf8),\n",
    "    pl.col('label').cast(pl.Int32)\n",
    "])\n",
    "\n",
    "negative_samples = negative_samples.with_columns([\n",
    "    pl.col('customerid').cast(pl.Utf8),\n",
    "    pl.col('product_code').cast(pl.Utf8),\n",
    "    pl.col('label').cast(pl.Int32)\n",
    "])\n",
    "\n",
    "# Combine positive and negative samples\n",
    "train_data = pl.concat([interaction_data_df, negative_samples], how='vertical')\n",
    "\n",
    "# Merge train_data with user_data and product_data\n",
    "train_data = train_data.join(user_data_encoded, on='customerid', how='left')\n",
    "train_data = train_data.join(product_data_encoded, on='product_code', how='left')\n",
    "\n",
    "# Shuffle the data\n",
    "train_data = train_data.sample(n=train_data.shape[0], shuffle=True, seed=42)\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_data_pandas, test_data_pandas = train_test_split(train_data.to_pandas(), test_size=0.2, random_state=42)\n",
    "train_data_pandas, val_data_pandas = train_test_split(train_data_pandas, test_size=0.125, random_state=42)  # 10% of original data\n",
    "\n",
    "# Convert back to Polars DataFrame\n",
    "train_data = pl.from_pandas(train_data_pandas)\n",
    "val_data = pl.from_pandas(val_data_pandas)\n",
    "test_data = pl.from_pandas(test_data_pandas)\n",
    "\n",
    "# Prepare the inputs for training\n",
    "def prepare_inputs(data, user_data_encoded, product_data_encoded):\n",
    "    user_data_dict = {row[0]: np.array(row[1:], dtype='float32') for row in user_data_encoded.iter_rows()}\n",
    "    product_data_dict = {row[0]: np.array(row[1:], dtype='float32') for row in product_data_encoded.iter_rows()}\n",
    "\n",
    "    user_inputs = []\n",
    "    product_inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for row in data.iter_rows():\n",
    "        user_id = row[0]\n",
    "        product_code = row[1]\n",
    "\n",
    "        if user_id in user_data_dict and product_code in product_data_dict:\n",
    "            user_inputs.append(user_data_dict[user_id])\n",
    "            product_inputs.append(product_data_dict[product_code])\n",
    "            labels.append(row[2])\n",
    "    \n",
    "    return np.array(user_inputs, dtype='float32'), np.array(product_inputs, dtype='float32'), np.array(labels, dtype='float32')\n",
    "\n",
    "train_user_inputs, train_product_inputs, train_labels = prepare_inputs(train_data, user_data_encoded, product_data_encoded)\n",
    "val_user_inputs, val_product_inputs, val_labels = prepare_inputs(val_data, user_data_encoded, product_data_encoded)\n",
    "test_user_inputs, test_product_inputs, test_labels = prepare_inputs(test_data, user_data_encoded, product_data_encoded)\n",
    "\n",
    "# Build the Two-Tower model\n",
    "def build_tower(input_shape, name):\n",
    "    inputs = Input(shape=(input_shape,), name=f'{name}_input')\n",
    "    x = Dense(64, activation='relu')(inputs)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    embedding = Dense(8)(x)\n",
    "    return Model(inputs, embedding, name=f'{name}_tower')\n",
    "\n",
    "user_input_shape = user_data_encoded.shape[1] - 1  # Exclude 'customerid'\n",
    "product_input_shape = product_data_encoded.shape[1] - 1  # Exclude 'product_code'\n",
    "\n",
    "user_tower = build_tower(user_input_shape, 'user')\n",
    "product_tower = build_tower(product_input_shape, 'product')\n",
    "\n",
    "user_input = Input(shape=(user_input_shape,), name='user_input')\n",
    "product_input = Input(shape=(product_input_shape,), name='product_input')\n",
    "\n",
    "user_embedding = user_tower(user_input)\n",
    "product_embedding = product_tower(product_input)\n",
    "\n",
    "dot_product = tf.reduce_sum(user_embedding * product_embedding, axis=-1)\n",
    "recommendation_model = Model([user_input, product_input], dot_product)\n",
    "\n",
    "recommendation_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with validation data\n",
    "recommendation_model.fit(\n",
    "    [train_user_inputs, train_product_inputs], train_labels, \n",
    "    validation_data=([val_user_inputs, val_product_inputs], val_labels),\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = recommendation_model.evaluate([test_user_inputs, test_product_inputs], test_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Print model summary\n",
    "recommendation_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step\n",
      "shape: (15_000, 4)\n",
      "┌────────────┬──────────────┬──────────────┬────────────────┐\n",
      "│ customerid ┆ product_code ┆ product_type ┆ probability    │\n",
      "│ ---        ┆ ---          ┆ ---          ┆ ---            │\n",
      "│ str        ┆ str          ┆ i64          ┆ f32            │\n",
      "╞════════════╪══════════════╪══════════════╪════════════════╡\n",
      "│ C1         ┆ P1           ┆ 1            ┆ -55976.804688  │\n",
      "│ C1         ┆ P13          ┆ 1            ┆ -88600.90625   │\n",
      "│ C1         ┆ P14          ┆ 1            ┆ -111576.453125 │\n",
      "│ C1         ┆ P15          ┆ 1            ┆ -145280.40625  │\n",
      "│ C1         ┆ P17          ┆ 1            ┆ -163554.75     │\n",
      "│ …          ┆ …            ┆ …            ┆ …              │\n",
      "│ C1500      ┆ P11          ┆ 0            ┆ -96899.28125   │\n",
      "│ C1500      ┆ P12          ┆ 0            ┆ -130541.289062 │\n",
      "│ C1500      ┆ P10          ┆ 0            ┆ -136010.34375  │\n",
      "│ C1500      ┆ P16          ┆ 0            ┆ -247593.234375 │\n",
      "│ C1500      ┆ P22          ┆ 0            ┆ -339606.0      │\n",
      "└────────────┴──────────────┴──────────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "# Generate synthetic user_data\n",
    "num_users = 1500\n",
    "num_products = 40\n",
    "\n",
    "user_ids = [f'C{i}' for i in range(1, num_users + 1)]\n",
    "product_codes = [f'P{i}' for i in range(1, num_products + 1)]\n",
    "\n",
    "user_data = pl.DataFrame({\n",
    "    'customerid': user_ids,\n",
    "    'age_group': np.random.choice(['20-30', '30-40', '40-50', '50-60', '60-70'], size=num_users),\n",
    "    'segment': np.random.choice(['Standard', 'Premium'], size=num_users),\n",
    "    'income': np.random.randint(30000, 100000, size=num_users),\n",
    "    'AUM': np.random.randint(50000, 150000, size=num_users)\n",
    "})\n",
    "\n",
    "product_data = pl.DataFrame({\n",
    "    'product_code': product_codes,\n",
    "    'product_name': [f'Product {i}' for i in range(1, num_products + 1)],\n",
    "    'product_type': np.random.choice(['Bond', 'Mutual Fund'], size=num_products),\n",
    "    'performance': np.random.uniform(5.0, 10.0, size=num_products)\n",
    "})\n",
    "\n",
    "# Encode categorical columns\n",
    "def encode_data(df, categorical_columns):\n",
    "    df_encoded = df.to_pandas()\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "    return pl.from_pandas(df_encoded)\n",
    "\n",
    "user_data_encoded = encode_data(user_data, ['age_group', 'segment'])\n",
    "product_data_encoded = encode_data(product_data, ['product_type', 'product_name'])\n",
    "\n",
    "# Prepare inputs for prediction\n",
    "def prepare_inputs(user_data_encoded, product_data_encoded):\n",
    "    user_data_dict = {row[0]: np.array(row[1:], dtype='float32') for row in user_data_encoded.iter_rows()}\n",
    "    product_data_dict = {row[0]: np.array(row[1:], dtype='float32') for row in product_data_encoded.iter_rows()}\n",
    "\n",
    "    for user_id in user_data_dict.keys():\n",
    "        for product_code in product_data_dict.keys():\n",
    "            yield user_data_dict[user_id], product_data_dict[product_code], user_id, product_code\n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 100000  # Adjust chunk size based on memory capacity\n",
    "\n",
    "# Function to predict in chunks and filter top 5 per product_type\n",
    "def predict_and_filter(user_data_encoded, product_data_encoded, model, chunk_size):\n",
    "    product_type_map = dict(zip(product_data_encoded['product_code'].to_pandas(), product_data_encoded['product_type'].to_pandas()))\n",
    "    \n",
    "    predictions_per_customer = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    inputs_gen = prepare_inputs(user_data_encoded, product_data_encoded)\n",
    "    chunk_user_inputs = []\n",
    "    chunk_product_inputs = []\n",
    "    chunk_combinations = []\n",
    "\n",
    "    for i, (user_input, product_input, user_id, product_code) in enumerate(inputs_gen):\n",
    "        chunk_user_inputs.append(user_input)\n",
    "        chunk_product_inputs.append(product_input)\n",
    "        chunk_combinations.append((user_id, product_code))\n",
    "        \n",
    "        if (i + 1) % chunk_size == 0:\n",
    "            user_inputs_batch = np.array(chunk_user_inputs, dtype='float32')\n",
    "            product_inputs_batch = np.array(chunk_product_inputs, dtype='float32')\n",
    "            chunk_predictions = model.predict([user_inputs_batch, product_inputs_batch])\n",
    "            \n",
    "            for (user_id, product_code), score in zip(chunk_combinations, chunk_predictions.flatten()):\n",
    "                product_type = product_type_map[product_code]\n",
    "                predictions_per_customer[user_id][product_type].append((product_code, score))\n",
    "            \n",
    "            chunk_user_inputs = []\n",
    "            chunk_product_inputs = []\n",
    "            chunk_combinations = []\n",
    "\n",
    "    # Process any remaining data\n",
    "    if chunk_user_inputs:\n",
    "        user_inputs_batch = np.array(chunk_user_inputs, dtype='float32')\n",
    "        product_inputs_batch = np.array(chunk_product_inputs, dtype='float32')\n",
    "        chunk_predictions = model.predict([user_inputs_batch, product_inputs_batch])\n",
    "        \n",
    "        for (user_id, product_code), score in zip(chunk_combinations, chunk_predictions.flatten()):\n",
    "            product_type = product_type_map[product_code]\n",
    "            predictions_per_customer[user_id][product_type].append((product_code, score))\n",
    "    \n",
    "    # Filter top 5 recommendations per customer and product_type\n",
    "    top_recommendations = []\n",
    "    \n",
    "    for user_id, product_types in predictions_per_customer.items():\n",
    "        for product_type, products_scores in product_types.items():\n",
    "            # Sort by score in descending order and select top 5\n",
    "            top_5 = sorted(products_scores, key=lambda x: x[1], reverse=True)[:5]\n",
    "            for product_code, score in top_5:\n",
    "                top_recommendations.append((user_id, product_code, product_type, score))\n",
    "    \n",
    "    return top_recommendations\n",
    "\n",
    "# Predict scores and filter top 5 recommendations\n",
    "top_recommendations = predict_and_filter(user_data_encoded, product_data_encoded, recommendation_model, chunk_size)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "top_recommendations_df = pd.DataFrame(top_recommendations, columns=['customerid', 'product_code', 'product_type', 'probability'])\n",
    "\n",
    "# Convert to Polars DataFrame if needed\n",
    "top_recommendations_pl_df = pl.from_pandas(top_recommendations_df)\n",
    "\n",
    "# Print the first few rows of the DataFrame with top recommendations\n",
    "print(top_recommendations_pl_df)\n",
    "\n",
    "# Optionally, save to CSV if needed\n",
    "# top_recommendations_pl_df.write_csv('top_recommendations.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
